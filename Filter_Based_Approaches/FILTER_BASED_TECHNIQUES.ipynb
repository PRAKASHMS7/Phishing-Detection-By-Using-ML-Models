{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNhQXODS1ogtnnZ1ZYLCm90",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAKASHMS7/Phishing-Detection-By-Using-ML-Models/blob/main/Filter_Based_Approaches/FILTER_BASED_TECHNIQUES.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INFORMATION GAIN**"
      ],
      "metadata": {
        "id": "TjOzI5YqHSFx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x0IW2la7HJAV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cc07a4e-74ea-4725-af2e-5080cbe6a009"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features with Information Gain Scores:\n",
            "Entropy_Domain: 1.081467\n",
            "pathurlRatio: 0.762876\n",
            "argPathRatio: 0.755385\n",
            "ArgUrlRatio: 0.751371\n",
            "argDomanRatio: 0.725091\n",
            "domainUrlRatio: 0.714127\n",
            "pathDomainRatio: 0.713744\n",
            "NumberRate_URL: 0.696469\n",
            "Entropy_DirectoryName: 0.677404\n",
            "CharacterContinuityRate: 0.655622\n",
            "NumberRate_FileName: 0.648979\n",
            "Entropy_Filename: 0.609906\n",
            "NumberRate_Extension: 0.553940\n",
            "avgpathtokenlen: 0.527027\n",
            "Entropy_Extension: 0.511696\n",
            "NumberRate_AfterPath: 0.502455\n",
            "Entropy_URL: 0.497878\n",
            "Entropy_Afterpath: 0.483615\n",
            "avgdomaintokenlen: 0.448818\n",
            "LongestPathTokenLength: 0.400368\n",
            "LongestVariableValue: 0.376572\n",
            "subDirLen: 0.367960\n",
            "pathLength: 0.366659\n",
            "urlLen: 0.364891\n",
            "NumberofDotsinURL: 0.360477\n",
            "ArgLen: 0.351163\n",
            "domainlength: 0.348375\n",
            "Querylength: 0.331870\n",
            "Query_LetterCount: 0.327048\n",
            "Extension_LetterCount: 0.323970\n",
            "Arguments_LongestWordLength: 0.306057\n",
            "host_letter_count: 0.305042\n",
            "domain_token_count: 0.296562\n",
            "SymbolCount_FileName: 0.295928\n",
            "SymbolCount_Domain: 0.294521\n",
            "tld: 0.294497\n",
            "Extension_DigitCount: 0.287756\n",
            "Query_DigitCount: 0.267815\n",
            "SymbolCount_Extension: 0.261461\n",
            "Filename_LetterCount: 0.261431\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy:    0.9709\n",
            "Precision:   0.9717\n",
            "Recall:      0.9706\n",
            "F1 Score:    0.9711\n",
            "ROC AUC:     0.9986\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.98      0.98      0.98      2434\n",
            "      benign       0.97      0.98      0.98      2329\n",
            "     malware       0.99      0.97      0.98      1984\n",
            "    phishing       0.93      0.95      0.94      2234\n",
            "        spam       0.99      0.97      0.98      2032\n",
            "\n",
            "    accuracy                           0.97     11013\n",
            "   macro avg       0.97      0.97      0.97     11013\n",
            "weighted avg       0.97      0.97      0.97     11013\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/All.csv')  # Change to your file path\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(data.select_dtypes(include=[np.number]))\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "target = label_encoder.fit_transform(data['URL_Type_obf_Type'])  # Replace with your target column\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Calculate Information Gain (Mutual Information)\n",
        "information_gain = mutual_info_classif(data_scaled, target)\n",
        "\n",
        "# Combine Information Gain scores with feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': data.select_dtypes(include=[np.number]).columns,\n",
        "    'Information_Gain': information_gain\n",
        "})\n",
        "\n",
        "# Sort features by Information Gain in descending order\n",
        "important_features = feature_importance.sort_values(by='Information_Gain', ascending=False)\n",
        "\n",
        "# Select the top 40 features based on Information Gain\n",
        "num_features_to_select = 40\n",
        "selected_features = important_features.head(num_features_to_select)\n",
        "\n",
        "# Display the selected features along with their Information Gain scores\n",
        "print(\"Selected Features with Information Gain Scores:\")\n",
        "for i, row in selected_features.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Information_Gain']:.6f}\")\n",
        "\n",
        "# Filter the dataset to keep only the selected features\n",
        "data_selected = pd.DataFrame(data_scaled, columns=data.select_dtypes(include=[np.number]).columns)[selected_features['Feature'].values]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_selected, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_probs = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr', average='macro')\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy:    {accuracy:.4f}\")\n",
        "print(f\"Precision:   {precision:.4f}\")\n",
        "print(f\"Recall:      {recall:.4f}\")\n",
        "print(f\"F1 Score:    {f1:.4f}\")\n",
        "print(f\"ROC AUC:     {roc_auc:.4f}\\n\")\n",
        "\n",
        "# Generate and display classification report\n",
        "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CHI SQUARE**"
      ],
      "metadata": {
        "id": "jTSwV6GJNryY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.preprocessing import LabelEncoder, KBinsDiscretizer, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/All.csv')  # Change to your file path\n",
        "\n",
        "# Encode the target variable (URL_Type_obf_Type)\n",
        "label_encoder = LabelEncoder()\n",
        "data['URL_Type_obf_Type'] = label_encoder.fit_transform(data['URL_Type_obf_Type'])\n",
        "\n",
        "# Handling missing values by filling them with median\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Replace infinite values with NaN and then fill NaN with the median\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Cap very large values to avoid overflow issues (adjust threshold if needed)\n",
        "threshold = 1e10\n",
        "data = data.clip(upper=threshold)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['URL_Type_obf_Type'])\n",
        "y = data['URL_Type_obf_Type']\n",
        "\n",
        "# Discretize continuous features for Chi-Square test\n",
        "discretizer = KBinsDiscretizer(n_bins=10, encode='ordinal', strategy='uniform')\n",
        "X_discretized = discretizer.fit_transform(X)\n",
        "\n",
        "# Apply Chi-Square test to select top 40 features\n",
        "chi2_selector = SelectKBest(chi2, k=40)\n",
        "X_kbest = chi2_selector.fit_transform(X_discretized, y)\n",
        "\n",
        "# Get feature scores and selected feature names\n",
        "selected_feature_indices = chi2_selector.get_support(indices=True)\n",
        "selected_features = X.columns[selected_feature_indices]\n",
        "chi2_scores = chi2_selector.scores_[selected_feature_indices]\n",
        "\n",
        "# Create a DataFrame for selected features and their Chi-Square scores\n",
        "chi2_results = pd.DataFrame({\n",
        "    'Feature': selected_features,\n",
        "    'Chi_Square_Score': chi2_scores\n",
        "}).sort_values(by='Chi_Square_Score', ascending=False)\n",
        "\n",
        "# Display the selected features along with their Chi-Square scores\n",
        "print(\"Selected Features with Chi-Square Scores:\")\n",
        "for i, row in enumerate(chi2_results.itertuples(), 1):\n",
        "    print(f\"{i}. {row.Feature}: {row.Chi_Square_Score:.6f}\")\n",
        "\n",
        "# Filter the dataset to keep only the selected features\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_selected)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_probs = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr', average='macro')\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy:    {accuracy:.4f}\")\n",
        "print(f\"Precision:   {precision:.4f}\")\n",
        "print(f\"Recall:      {recall:.4f}\")\n",
        "print(f\"F1 Score:    {f1:.4f}\")\n",
        "print(f\"ROC AUC:     {roc_auc:.4f}\\n\")\n",
        "\n",
        "# Generate and display classification report\n",
        "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMB5c_FZN3UI",
        "outputId": "d823d3d5-758a-4a2c-b7a5-d0ef62843b4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_discretization.py:262: UserWarning: Feature 35 is constant and will be replaced with 0.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features with Chi-Square Scores:\n",
            "1. Entropy_Afterpath: 46636.348497\n",
            "2. ArgUrlRatio: 32560.235238\n",
            "3. NumberRate_AfterPath: 30911.488374\n",
            "4. argPathRatio: 17623.597596\n",
            "5. Extension_DigitCount: 14657.170524\n",
            "6. NumberRate_Domain: 12832.426467\n",
            "7. URLQueries_variable: 12516.599730\n",
            "8. SymbolCount_Extension: 12484.431530\n",
            "9. delimeter_Count: 12140.969209\n",
            "10. SymbolCount_FileName: 12048.976722\n",
            "11. Query_DigitCount: 11321.997078\n",
            "12. LongestVariableValue: 10674.628574\n",
            "13. Query_LetterCount: 10371.595582\n",
            "14. Querylength: 10337.045398\n",
            "15. ArgLen: 10134.795668\n",
            "16. Extension_LetterCount: 10056.335110\n",
            "17. URL_DigitCount: 9857.789986\n",
            "18. argDomanRatio: 9761.104868\n",
            "19. ldl_getArg: 9646.693640\n",
            "20. URL_Letter_Count: 9562.160085\n",
            "21. LongestPathTokenLength: 9491.649772\n",
            "22. ldl_path: 9470.442753\n",
            "23. domainUrlRatio: 9423.584553\n",
            "24. ldl_url: 9405.311557\n",
            "25. urlLen: 9065.048105\n",
            "26. dld_getArg: 8936.258383\n",
            "27. subDirLen: 8902.172790\n",
            "28. pathLength: 8902.172790\n",
            "29. SymbolCount_URL: 8495.513886\n",
            "30. SymbolCount_Afterpath: 8220.950744\n",
            "31. charcompace: 7078.741261\n",
            "32. dld_path: 7060.087266\n",
            "33. delimeter_path: 6945.228491\n",
            "34. Arguments_LongestWordLength: 6875.217093\n",
            "35. NumberofDotsinURL: 6493.396729\n",
            "36. pathDomainRatio: 6389.385932\n",
            "37. dld_url: 5984.527723\n",
            "38. spcharUrl: 5810.799527\n",
            "39. NumberRate_URL: 5470.495147\n",
            "40. SymbolCount_Directoryname: 5422.443821\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy:    0.9597\n",
            "Precision:   0.9607\n",
            "Recall:      0.9596\n",
            "F1 Score:    0.9601\n",
            "ROC AUC:     0.9974\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.97      0.96      0.96      2434\n",
            "      benign       0.97      0.98      0.97      2329\n",
            "     malware       0.98      0.97      0.98      1984\n",
            "    phishing       0.91      0.94      0.93      2234\n",
            "        spam       0.98      0.95      0.96      2032\n",
            "\n",
            "    accuracy                           0.96     11013\n",
            "   macro avg       0.96      0.96      0.96     11013\n",
            "weighted avg       0.96      0.96      0.96     11013\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FISHER SCORE**"
      ],
      "metadata": {
        "id": "J4ZyFiQAOAoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/All.csv')  # Change to your file path\n",
        "\n",
        "# Encode the target variable (URL_Type_obf_Type)\n",
        "label_encoder = LabelEncoder()\n",
        "data['URL_Type_obf_Type'] = label_encoder.fit_transform(data['URL_Type_obf_Type'])\n",
        "\n",
        "# Handling missing values by filling them with median\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Replace infinite values with NaN and then fill NaN with the median\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Cap very large values to avoid overflow issues (adjust threshold if needed)\n",
        "threshold = 1e10\n",
        "data = data.clip(upper=threshold)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['URL_Type_obf_Type'])\n",
        "y = data['URL_Type_obf_Type']\n",
        "\n",
        "# Apply Fisher Score (ANOVA F-value) for feature ranking\n",
        "fisher_scores, _ = f_classif(X, y)\n",
        "\n",
        "# Create a DataFrame for features and their Fisher Scores\n",
        "fisher_results = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Fisher_Score': fisher_scores\n",
        "}).sort_values(by='Fisher_Score', ascending=False)\n",
        "\n",
        "# Select only the top 40 features\n",
        "top_40_features = fisher_results.head(40)\n",
        "selected_features = top_40_features['Feature'].values\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_prob = clf.predict_proba(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
        "\n",
        "# Generate classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the selected features along with their Fisher Scores\n",
        "print(\"Top 40 Features with Fisher Scores:\")\n",
        "for i, row in enumerate(top_40_features.itertuples(), 1):\n",
        "    print(f\"{i}. {row.Feature}: {row.Fisher_Score:.6f}\")\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wK2SBTn7OEb4",
        "outputId": "7b222ddb-060c-4cb3-9e60-668137b8b6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [35] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 40 Features with Fisher Scores:\n",
            "1. SymbolCount_Domain: 3528.923323\n",
            "2. domain_token_count: 3505.067755\n",
            "3. tld: 3505.067755\n",
            "4. Entropy_Afterpath: 3473.507167\n",
            "5. NumberRate_AfterPath: 3424.144460\n",
            "6. ArgUrlRatio: 3114.109486\n",
            "7. domainUrlRatio: 2788.370617\n",
            "8. URLQueries_variable: 2653.092646\n",
            "9. SymbolCount_FileName: 2647.994462\n",
            "10. argPathRatio: 2551.406432\n",
            "11. delimeter_path: 2525.575957\n",
            "12. delimeter_Count: 2524.101710\n",
            "13. pathurlRatio: 2490.365833\n",
            "14. SymbolCount_Extension: 2336.347730\n",
            "15. SymbolCount_URL: 2301.843351\n",
            "16. NumberofDotsinURL: 2211.422943\n",
            "17. Arguments_LongestWordLength: 2152.619875\n",
            "18. SymbolCount_Afterpath: 2059.704300\n",
            "19. CharacterContinuityRate: 1973.611670\n",
            "20. domainlength: 1951.540466\n",
            "21. host_letter_count: 1891.533403\n",
            "22. Extension_DigitCount: 1874.519721\n",
            "23. spcharUrl: 1549.892671\n",
            "24. SymbolCount_Directoryname: 1486.539534\n",
            "25. Entropy_Extension: 1445.690235\n",
            "26. avgdomaintokenlen: 1370.316894\n",
            "27. Query_DigitCount: 1363.660739\n",
            "28. URL_DigitCount: 1360.412324\n",
            "29. Entropy_Domain: 1326.917387\n",
            "30. longdomaintokenlen: 1232.807420\n",
            "31. path_token_count: 1194.164952\n",
            "32. dld_getArg: 1172.077420\n",
            "33. ArgLen: 1144.284617\n",
            "34. NumberRate_Extension: 1110.793808\n",
            "35. NumberRate_Domain: 1060.009570\n",
            "36. dld_path: 1053.555557\n",
            "37. dld_url: 1049.717127\n",
            "38. charcompace: 968.782089\n",
            "39. argDomanRatio: 963.224687\n",
            "40. subDirLen: 921.103503\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy: 0.9736\n",
            "Precision: 0.9736\n",
            "Recall: 0.9736\n",
            "F1 Score: 0.9736\n",
            "ROC AUC: 0.9988\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1628\n",
            "           1       0.97      0.99      0.98      1526\n",
            "           2       0.99      0.98      0.98      1332\n",
            "           3       0.95      0.94      0.94      1497\n",
            "           4       0.99      0.98      0.99      1359\n",
            "\n",
            "    accuracy                           0.97      7342\n",
            "   macro avg       0.97      0.97      0.97      7342\n",
            "weighted avg       0.97      0.97      0.97      7342\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MISSING VALUE R**ATIO"
      ],
      "metadata": {
        "id": "GQu3MyBQDlM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/All.csv')  # Update with your file path\n",
        "\n",
        "# Calculate the missing value ratio for each feature\n",
        "missing_ratio = data.isnull().mean()\n",
        "\n",
        "# Select the top 40 features with the highest missing value ratios\n",
        "top_40_missing_features = missing_ratio.sort_values(ascending=False).head(40).index\n",
        "\n",
        "# Display the top 40 features with their missing value ratios\n",
        "print(\"Top 40 Features with Highest Missing Value Ratios:\")\n",
        "for feature in top_40_missing_features:\n",
        "    print(f\"{feature}: {missing_ratio[feature]:.2%}\")\n",
        "\n",
        "# Filter the dataset to include only the selected features and the target variable\n",
        "selected_data = data[top_40_missing_features.tolist() + ['URL_Type_obf_Type']]\n",
        "\n",
        "# Separate features and target variable\n",
        "X = selected_data.drop(columns=['URL_Type_obf_Type'])\n",
        "y = selected_data['URL_Type_obf_Type']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Preprocessing for numerical data: impute missing values with median\n",
        "numerical_transformer = SimpleImputer(strategy='median')\n",
        "\n",
        "# Preprocessing for categorical data: impute missing values with most frequent value, then one-hot encode\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Bundle preprocessing for numerical and categorical data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Create a preprocessing and modeling pipeline\n",
        "model = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                        ('scaler', StandardScaler(with_mean=False)),  # StandardScaler doesn't support sparse matrices\n",
        "                        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))])\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = model.predict(X_test)\n",
        "y_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')  # Use 'weighted' for multiclass\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
        "\n",
        "# Print classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SIMWcab5Djpo",
        "outputId": "3bcb6d4d-e9d1-4caa-aa9a-e99cb6de8da7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 40 Features with Highest Missing Value Ratios:\n",
            "NumberRate_Extension: 27.60%\n",
            "Entropy_DirectoryName: 23.07%\n",
            "avgpathtokenlen: 0.76%\n",
            "Entropy_Filename: 0.64%\n",
            "Entropy_Extension: 0.11%\n",
            "NumberRate_FileName: 0.03%\n",
            "NumberRate_DirectoryName: 0.03%\n",
            "Entropy_Afterpath: 0.02%\n",
            "NumberRate_AfterPath: 0.01%\n",
            "Querylength: 0.00%\n",
            "path_token_count: 0.00%\n",
            "domain_token_count: 0.00%\n",
            "avgdomaintokenlen: 0.00%\n",
            "longdomaintokenlen: 0.00%\n",
            "tld: 0.00%\n",
            "charcompvowels: 0.00%\n",
            "dld_domain: 0.00%\n",
            "dld_url: 0.00%\n",
            "ldl_getArg: 0.00%\n",
            "ldl_filename: 0.00%\n",
            "ldl_path: 0.00%\n",
            "ldl_domain: 0.00%\n",
            "ldl_url: 0.00%\n",
            "charcompace: 0.00%\n",
            "dld_path: 0.00%\n",
            "dld_filename: 0.00%\n",
            "dld_getArg: 0.00%\n",
            "urlLen: 0.00%\n",
            "domainlength: 0.00%\n",
            "pathLength: 0.00%\n",
            "subDirLen: 0.00%\n",
            "fileNameLen: 0.00%\n",
            "executable: 0.00%\n",
            "isPortEighty: 0.00%\n",
            "NumberofDotsinURL: 0.00%\n",
            "ISIpAddressInDomainName: 0.00%\n",
            "CharacterContinuityRate: 0.00%\n",
            "LongestVariableValue: 0.00%\n",
            "URL_DigitCount: 0.00%\n",
            "host_DigitCount: 0.00%\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy:  0.9695\n",
            "Precision: 0.9698\n",
            "Recall:    0.9695\n",
            "F1 Score:  0.9696\n",
            "ROC AUC:   0.9985\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.98      0.98      0.98      1628\n",
            "      benign       0.96      0.99      0.98      1526\n",
            "     malware       0.99      0.96      0.98      1332\n",
            "    phishing       0.93      0.94      0.94      1497\n",
            "        spam       0.99      0.97      0.98      1359\n",
            "\n",
            "    accuracy                           0.97      7342\n",
            "   macro avg       0.97      0.97      0.97      7342\n",
            "weighted avg       0.97      0.97      0.97      7342\n",
            "\n"
          ]
        }
      ]
    }
  ]
}