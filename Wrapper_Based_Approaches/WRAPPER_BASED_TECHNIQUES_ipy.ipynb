{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAKASHMS7/Phishing-Detection-By-Using-ML-Models/blob/main/Wrapper_Based_Approaches/WRAPPER_BASED_TECHNIQUES_ipy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JFt5sdCQOlK"
      },
      "source": [
        "**FORWARD SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2S2KPHhquiG",
        "outputId": "90b48504-7c7b-4ebd-f3b4-3322545daef2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-2-ff718aa33814>:24: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
            "  X = X.applymap(lambda x: np.nan if isinstance(x, float) and (x > 1e308 or x < -1e308) else x)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 40 Selected Features:\n",
            "\n",
            "1. domain_token_count\n",
            "2. avgdomaintokenlen\n",
            "3. longdomaintokenlen\n",
            "4. ldl_url\n",
            "5. ldl_domain\n",
            "6. ldl_getArg\n",
            "7. dld_domain\n",
            "8. dld_getArg\n",
            "9. domainlength\n",
            "10. fileNameLen\n",
            "11. this.fileExtLen\n",
            "12. ArgUrlRatio\n",
            "13. argDomanRatio\n",
            "14. executable\n",
            "15. isPortEighty\n",
            "16. NumberofDotsinURL\n",
            "17. ISIpAddressInDomainName\n",
            "18. CharacterContinuityRate\n",
            "19. URL_DigitCount\n",
            "20. host_DigitCount\n",
            "21. Directory_DigitCount\n",
            "22. File_name_DigitCount\n",
            "23. Extension_DigitCount\n",
            "24. host_letter_count\n",
            "25. Directory_LetterCount\n",
            "26. Filename_LetterCount\n",
            "27. Extension_LetterCount\n",
            "28. Domain_LongestWordLength\n",
            "29. Path_LongestWordLength\n",
            "30. Arguments_LongestWordLength\n",
            "31. URLQueries_variable\n",
            "32. spcharUrl\n",
            "33. delimeter_Domain\n",
            "34. delimeter_path\n",
            "35. NumberRate_URL\n",
            "36. NumberRate_Domain\n",
            "37. NumberRate_DirectoryName\n",
            "38. SymbolCount_Domain\n",
            "39. SymbolCount_Directoryname\n",
            "40. Entropy_Domain\n",
            "\n",
            "Evaluation Metrics on Selected Features:\n",
            "Accuracy:  0.9564\n",
            "Precision: 0.9574\n",
            "Recall:    0.9564\n",
            "F1 Score:  0.9566\n",
            "ROC AUC:   0.9971\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "# Load the dataset\n",
        "file_path = '/content/All.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"All.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['URL_Type_obf_Type'])\n",
        "y = df['URL_Type_obf_Type']\n",
        "\n",
        "# Clean data: Replace inf and very large values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "X = X.applymap(lambda x: np.nan if isinstance(x, float) and (x > 1e308 or x < -1e308) else x)\n",
        "\n",
        "# Impute missing values using column mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Take a sample for faster computation\n",
        "X_sample, _, y_sample, _ = train_test_split(X_imputed, y_encoded, train_size=0.3, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Define classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Forward Feature Selection (Top 40)\n",
        "sfs = SequentialFeatureSelector(clf, n_features_to_select=40, direction='forward', scoring='accuracy', cv=3, n_jobs=-1)\n",
        "sfs.fit(X_sample, y_sample)\n",
        "\n",
        "# Get selected features\n",
        "selected_features = X_sample.columns[sfs.get_support()].tolist()\n",
        "\n",
        "# Train-test split with selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_sample[selected_features], y_sample, test_size=0.3, random_state=42, stratify=y_sample)\n",
        "\n",
        "# Train and predict\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "y_prob = clf.predict_proba(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop 40 Selected Features:\\n\")\n",
        "for i, feat in enumerate(selected_features, 1):\n",
        "    print(f\"{i}. {feat}\")\n",
        "\n",
        "print(\"\\nEvaluation Metrics on Selected Features:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"ROC AUC:   {roc_auc:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvAQ1VRqQv0Z"
      },
      "source": [
        "**BACKWARD SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1-2ko6JWTn7",
        "outputId": "ffd2025e-a5a8-4ad7-feae-a0d66ff47067"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.4s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Backward selection completed in 16.69 minutes\n",
            "\n",
            "Top 40 Selected Features (Backward Selection):\n",
            "\n",
            "1. dld_url\n",
            "2. Directory_DigitCount\n",
            "3. charcompvowels\n",
            "4. Entropy_URL\n",
            "5. LongestVariableValue\n",
            "6. Entropy_Extension\n",
            "7. File_name_DigitCount\n",
            "8. Filename_LetterCount\n",
            "9. path_token_count\n",
            "10. host_DigitCount\n",
            "11. fileNameLen\n",
            "12. URL_DigitCount\n",
            "13. Querylength\n",
            "14. NumberRate_AfterPath\n",
            "15. SymbolCount_FileName\n",
            "16. Query_LetterCount\n",
            "17. ldl_url\n",
            "18. argPathRatio\n",
            "19. Query_DigitCount\n",
            "20. longdomaintokenlen\n",
            "21. Domain_LongestWordLength\n",
            "22. Extension_LetterCount\n",
            "23. LongestPathTokenLength\n",
            "24. delimeter_path\n",
            "25. URLQueries_variable\n",
            "26. NumberRate_Extension\n",
            "27. NumberRate_URL\n",
            "28. domain_token_count\n",
            "29. argDomanRatio\n",
            "30. CharacterContinuityRate\n",
            "31. SymbolCount_Directoryname\n",
            "32. Entropy_Domain\n",
            "33. spcharUrl\n",
            "34. avgpathtokenlen\n",
            "35. avgdomaintokenlen\n",
            "36. domainlength\n",
            "37. host_letter_count\n",
            "38. NumberRate_FileName\n",
            "39. ArgUrlRatio\n",
            "40. tld\n",
            "\n",
            "Evaluation Metrics on Selected Features:\n",
            "Accuracy:  0.9514\n",
            "Precision: 0.9522\n",
            "Recall:    0.9514\n",
            "F1 Score:  0.9515\n",
            "ROC AUC:   0.9951\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"All.csv\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['URL_Type_obf_Type'])\n",
        "y = df['URL_Type_obf_Type']\n",
        "\n",
        "# Clean data: Replace inf and very large values with NaN\n",
        "X.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Update deprecated applymap with column-wise map\n",
        "for col in X.columns:\n",
        "    X[col] = X[col].map(lambda x: np.nan if isinstance(x, float) and (x > 1e308 or x < -1e308) else x)\n",
        "\n",
        "# Impute missing values using column mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Take a smaller sample for faster computation\n",
        "X_sample, _, y_sample, _ = train_test_split(X_imputed, y_encoded, train_size=0.2, stratify=y_encoded, random_state=42)\n",
        "\n",
        "# Define classifier with optimized parameters for faster execution\n",
        "clf = RandomForestClassifier(\n",
        "    n_estimators=50,\n",
        "    max_depth=10,\n",
        "    min_samples_split=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Backward Feature Selection with optimizations\n",
        "start_time = time.time()\n",
        "\n",
        "# First reduce features using feature importance\n",
        "clf.fit(X_sample, y_sample)\n",
        "importances = clf.feature_importances_\n",
        "top_60_features = X_sample.columns[np.argsort(importances)[-60:]]\n",
        "X_reduced = X_sample[top_60_features]\n",
        "\n",
        "# Perform backward selection on reduced set\n",
        "sfs_backward = SequentialFeatureSelector(\n",
        "    clf,\n",
        "    n_features_to_select=40,\n",
        "    direction='backward',\n",
        "    scoring='accuracy',\n",
        "    cv=2,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "sfs_backward.fit(X_reduced, y_sample)\n",
        "selected_features = X_reduced.columns[sfs_backward.get_support()].tolist()\n",
        "\n",
        "print(f\"\\nBackward selection completed in {(time.time() - start_time)/60:.2f} minutes\")\n",
        "\n",
        "# Train-test split with selected features\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_sample[selected_features], y_sample,\n",
        "    test_size=0.3,\n",
        "    random_state=42,\n",
        "    stratify=y_sample\n",
        ")\n",
        "\n",
        "# Train and predict with final classifier\n",
        "final_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "final_clf.fit(X_train, y_train)\n",
        "y_pred = final_clf.predict(X_test)\n",
        "y_prob = final_clf.predict_proba(X_test)\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_prob, multi_class='ovr')\n",
        "\n",
        "# Display results\n",
        "print(\"\\nTop 40 Selected Features (Backward Selection):\\n\")\n",
        "for i, feat in enumerate(selected_features, 1):\n",
        "    print(f\"{i}. {feat}\")\n",
        "\n",
        "print(\"\\nEvaluation Metrics on Selected Features:\")\n",
        "print(f\"Accuracy:  {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall:    {recall:.4f}\")\n",
        "print(f\"F1 Score:  {f1:.4f}\")\n",
        "print(f\"ROC AUC:   {roc_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ_7Qg_ySySi"
      },
      "source": [
        "**EXHAUSTIVE SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCAgk1ykgeUx",
        "outputId": "b9a99289-818a-4396-b89c-55bc72a0fe1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading and preprocessing data...\n",
            "\n",
            "Performing feature selection (RFE)...\n",
            "Fitting estimator with 79 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting estimator with 72 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting estimator with 65 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting estimator with 58 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting estimator with 51 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting estimator with 44 features.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== TOP 40 SELECTED FEATURES ===\n",
            " 1. Querylength\n",
            " 2. domain_token_count\n",
            " 3. path_token_count\n",
            " 4. avgdomaintokenlen\n",
            " 5. longdomaintokenlen\n",
            " 6. tld\n",
            " 7. charcompvowels\n",
            " 8. ldl_url\n",
            " 9. ldl_path\n",
            "10. ldl_getArg\n",
            "11. dld_url\n",
            "12. dld_getArg\n",
            "13. urlLen\n",
            "14. domainlength\n",
            "15. pathLength\n",
            "16. subDirLen\n",
            "17. ArgLen\n",
            "18. pathurlRatio\n",
            "19. ArgUrlRatio\n",
            "20. argDomanRatio\n",
            "21. domainUrlRatio\n",
            "22. pathDomainRatio\n",
            "23. argPathRatio\n",
            "24. LongestVariableValue\n",
            "25. URL_DigitCount\n",
            "26. host_DigitCount\n",
            "27. Extension_DigitCount\n",
            "28. Query_DigitCount\n",
            "29. URL_Letter_Count\n",
            "30. host_letter_count\n",
            "31. Extension_LetterCount\n",
            "32. Query_LetterCount\n",
            "33. LongestPathTokenLength\n",
            "34. URLQueries_variable\n",
            "35. delimeter_path\n",
            "36. NumberRate_Domain\n",
            "37. NumberRate_AfterPath\n",
            "38. SymbolCount_URL\n",
            "39. SymbolCount_Domain\n",
            "40. SymbolCount_Afterpath\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1271: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 2.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== MODEL PERFORMANCE ===\n",
            "Accuracy:  0.7996\n",
            "Precision: 0.8050\n",
            "Recall:    0.7996\n",
            "F1 Score:  0.7976\n",
            "ROC AUC:   0.9564\n",
            "\n",
            "=== CLASSIFICATION REPORT ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.82      0.79      0.81      1586\n",
            "      benign       0.78      0.87      0.82      1556\n",
            "     malware       0.82      0.61      0.70      1343\n",
            "    phishing       0.72      0.85      0.78      1517\n",
            "        spam       0.89      0.86      0.87      1340\n",
            "\n",
            "    accuracy                           0.80      7342\n",
            "   macro avg       0.81      0.80      0.80      7342\n",
            "weighted avg       0.81      0.80      0.80      7342\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "def load_and_preprocess(filepath):\n",
        "    \"\"\"Optimized data loading and preprocessing\"\"\"\n",
        "    data = pd.read_csv(filepath)\n",
        "\n",
        "    # Handle missing values\n",
        "    data = data.fillna(data.median(numeric_only=True))\n",
        "\n",
        "    # Encode target\n",
        "    le = LabelEncoder()\n",
        "    data['URL_Type_obf_Type'] = le.fit_transform(data['URL_Type_obf_Type'])\n",
        "\n",
        "    # Separate features and target\n",
        "    X = data.select_dtypes(include=[np.number]).drop(columns=['URL_Type_obf_Type'], errors='ignore')\n",
        "    y = data['URL_Type_obf_Type']\n",
        "\n",
        "    # Handle infinite values\n",
        "    X = X.replace([np.inf, -np.inf], np.nan).fillna(X.median())\n",
        "\n",
        "    return X, y, le\n",
        "\n",
        "def main():\n",
        "    # Load and preprocess\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    X, y, le = load_and_preprocess(\"/content/All.csv\")\n",
        "\n",
        "    # Standardize\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    model = LogisticRegression(max_iter=1000, solver='liblinear', n_jobs=-1)\n",
        "\n",
        "    # Faster feature selection using RFE\n",
        "    print(\"\\nPerforming feature selection (RFE)...\")\n",
        "    selector = RFE(model, n_features_to_select=40, step=0.1, verbose=1)\n",
        "    selector.fit(X_train, y_train)\n",
        "\n",
        "    # Get selected features\n",
        "    selected_features = X.columns[selector.support_]\n",
        "\n",
        "    print(\"\\n=== TOP 40 SELECTED FEATURES ===\")\n",
        "    for i, feat in enumerate(selected_features, 1):\n",
        "        print(f\"{i:2d}. {feat}\")\n",
        "\n",
        "    # Train on selected features\n",
        "    X_train_selected = selector.transform(X_train)\n",
        "    X_test_selected = selector.transform(X_test)\n",
        "\n",
        "    model.fit(X_train_selected, y_train)\n",
        "\n",
        "    # Evaluate\n",
        "    y_pred = model.predict(X_test_selected)\n",
        "    y_proba = model.predict_proba(X_test_selected)\n",
        "\n",
        "    print(\"\\n=== MODEL PERFORMANCE ===\")\n",
        "    print(f\"Accuracy:  {accuracy_score(y_test, y_pred):.4f}\")\n",
        "    print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"Recall:    {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"F1 Score:  {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "    print(f\"ROC AUC:   {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}\")\n",
        "\n",
        "    print(\"\\n=== CLASSIFICATION REPORT ===\")\n",
        "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxXjiX7FT_-q"
      },
      "source": [
        "**RECURSIVE SELECTION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxbTLWEW-ifR",
        "outputId": "26667480-a2f6-40cd-ab54-ab19c2580cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Infinity check: False\n",
            "NaN check: False\n",
            "\n",
            "Top 40 Features by Importance:\n",
            "                  Feature  Importance\n",
            "        avgdomaintokenlen    0.036005\n",
            "                   urlLen    0.027954\n",
            "      NumberRate_FileName    0.027417\n",
            "    Extension_LetterCount    0.027204\n",
            "     Extension_DigitCount    0.026785\n",
            "             domainlength    0.025742\n",
            "       SymbolCount_Domain    0.025150\n",
            "             pathurlRatio    0.024794\n",
            "               pathLength    0.023207\n",
            "       domain_token_count    0.022612\n",
            "  CharacterContinuityRate    0.022581\n",
            "              fileNameLen    0.022316\n",
            "           domainUrlRatio    0.022299\n",
            "                subDirLen    0.022251\n",
            "                      tld    0.022210\n",
            "          pathDomainRatio    0.021146\n",
            "   LongestPathTokenLength    0.020505\n",
            "           NumberRate_URL    0.020428\n",
            "           Entropy_Domain    0.020219\n",
            "            argDomanRatio    0.019985\n",
            "       longdomaintokenlen    0.019727\n",
            "        host_letter_count    0.018471\n",
            "    Directory_LetterCount    0.018396\n",
            "        NumberofDotsinURL    0.018364\n",
            "              ArgUrlRatio    0.018132\n",
            "     NumberRate_Extension    0.017463\n",
            "         URL_Letter_Count    0.016956\n",
            "          avgpathtokenlen    0.015792\n",
            "         Entropy_Filename    0.015356\n",
            "    Entropy_DirectoryName    0.015266\n",
            "     Filename_LetterCount    0.014364\n",
            " Domain_LongestWordLength    0.014311\n",
            "           delimeter_path    0.013615\n",
            "             argPathRatio    0.013602\n",
            "        NumberRate_Domain    0.013442\n",
            "SymbolCount_Directoryname    0.012004\n",
            "           URL_DigitCount    0.011627\n",
            "     File_name_DigitCount    0.011460\n",
            "          SymbolCount_URL    0.011441\n",
            "          this.fileExtLen    0.010792\n",
            "\n",
            "Model Metrics:\n",
            "Accuracy: 0.9679\n",
            "Precision: 0.9682\n",
            "Recall: 0.9679\n",
            "F1 Score: 0.9680\n",
            "ROC AUC: 0.9978\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.97      0.97      0.97       719\n",
            "      benign       0.96      0.96      0.96       806\n",
            "     malware       0.99      0.98      0.99      1347\n",
            "    phishing       0.92      0.94      0.93      1222\n",
            "        spam       0.99      0.98      0.98      1601\n",
            "\n",
            "    accuracy                           0.97      5695\n",
            "   macro avg       0.97      0.97      0.97      5695\n",
            "weighted avg       0.97      0.97      0.97      5695\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (accuracy_score, precision_score,\n",
        "                           recall_score, f1_score, roc_auc_score,\n",
        "                           classification_report)\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('/content/All.csv')\n",
        "\n",
        "# Handle infinite and missing values\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
        "data.dropna(inplace=True)  # Remove rows with any NaN values\n",
        "\n",
        "# Verify no infinite or NaN values remain\n",
        "print(\"Infinity check:\", np.isinf(data.select_dtypes(include=np.number)).any().any())\n",
        "print(\"NaN check:\", data.isna().any().any())\n",
        "\n",
        "# Prepare features/target\n",
        "X = data.drop(columns='URL_Type_obf_Type')\n",
        "y = data['URL_Type_obf_Type']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Get feature importance\n",
        "model = RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train, y_train)  # This should now work\n",
        "\n",
        "# Select top 40 features\n",
        "importance = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
        "top_40 = importance.nlargest(40, 'Importance')\n",
        "\n",
        "# Display features\n",
        "print(\"\\nTop 40 Features by Importance:\")\n",
        "print(top_40.to_string(index=False))\n",
        "\n",
        "# Train model with selected features\n",
        "model.fit(X_train[top_40['Feature']], y_train)\n",
        "y_pred = model.predict(X_test[top_40['Feature']])\n",
        "y_proba = model.predict_proba(X_test[top_40['Feature']])\n",
        "\n",
        "# Compute metrics\n",
        "print(\"\\nModel Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(y_test, y_pred, average='weighted'):.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc_score(y_test, y_proba, multi_class='ovr'):.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9IBICdWGNIfulp8hT5aaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}