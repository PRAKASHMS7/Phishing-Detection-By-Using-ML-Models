{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoJvCMGwQZmtNt3BA+9RFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAKASHMS7/Phishing-Detection-By-Using-ML-Models/blob/main/Filter_Based_Approach/FISHER_SCORE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import f_classif\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/All.csv')  # Change to your file path\n",
        "\n",
        "# Encode the target variable (URL_Type_obf_Type)\n",
        "label_encoder = LabelEncoder()\n",
        "data['URL_Type_obf_Type'] = label_encoder.fit_transform(data['URL_Type_obf_Type'])\n",
        "\n",
        "# Handling missing values by filling them with median\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Replace infinite values with NaN and then fill NaN with the median\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "data.fillna(data.median(numeric_only=True), inplace=True)\n",
        "\n",
        "# Cap very large values to avoid overflow issues (adjust threshold if needed)\n",
        "threshold = 1e10\n",
        "data = data.clip(upper=threshold)\n",
        "\n",
        "# Separate features and target\n",
        "X = data.drop(columns=['URL_Type_obf_Type'])\n",
        "y = data['URL_Type_obf_Type']\n",
        "\n",
        "# Apply Fisher Score (ANOVA F-value) for feature ranking\n",
        "fisher_scores, _ = f_classif(X, y)\n",
        "\n",
        "# Create a DataFrame for features and their Fisher Scores\n",
        "fisher_results = pd.DataFrame({\n",
        "    'Feature': X.columns,\n",
        "    'Fisher_Score': fisher_scores\n",
        "}).sort_values(by='Fisher_Score', ascending=False)\n",
        "\n",
        "# Select only the top 40 features\n",
        "top_40_features = fisher_results.head(40)\n",
        "selected_features = top_40_features['Feature'].values\n",
        "\n",
        "# Split dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X[selected_features], y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "y_pred_prob = clf.predict_proba(X_test)\n",
        "\n",
        "# Compute evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "roc_auc = roc_auc_score(y_test, y_pred_prob, multi_class='ovr')\n",
        "\n",
        "# Generate classification report\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "# Display the selected features along with their Fisher Scores\n",
        "print(\"Top 40 Features with Fisher Scores:\")\n",
        "for i, row in enumerate(top_40_features.itertuples(), 1):\n",
        "    print(f\"{i}. {row.Feature}: {row.Fisher_Score:.6f}\")\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1HwxoF-zzrP",
        "outputId": "45b02dc9-6561-4499-ce7b-01e0a1a0e2b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [35] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 40 Features with Fisher Scores:\n",
            "1. SymbolCount_Domain: 3528.923323\n",
            "2. domain_token_count: 3505.067755\n",
            "3. tld: 3505.067755\n",
            "4. Entropy_Afterpath: 3473.507167\n",
            "5. NumberRate_AfterPath: 3424.144460\n",
            "6. ArgUrlRatio: 3114.109486\n",
            "7. domainUrlRatio: 2788.370617\n",
            "8. URLQueries_variable: 2653.092646\n",
            "9. SymbolCount_FileName: 2647.994462\n",
            "10. argPathRatio: 2551.406432\n",
            "11. delimeter_path: 2525.575957\n",
            "12. delimeter_Count: 2524.101710\n",
            "13. pathurlRatio: 2490.365833\n",
            "14. SymbolCount_Extension: 2336.347730\n",
            "15. SymbolCount_URL: 2301.843351\n",
            "16. NumberofDotsinURL: 2211.422943\n",
            "17. Arguments_LongestWordLength: 2152.619875\n",
            "18. SymbolCount_Afterpath: 2059.704300\n",
            "19. CharacterContinuityRate: 1973.611670\n",
            "20. domainlength: 1951.540466\n",
            "21. host_letter_count: 1891.533403\n",
            "22. Extension_DigitCount: 1874.519721\n",
            "23. spcharUrl: 1549.892671\n",
            "24. SymbolCount_Directoryname: 1486.539534\n",
            "25. Entropy_Extension: 1445.690235\n",
            "26. avgdomaintokenlen: 1370.316894\n",
            "27. Query_DigitCount: 1363.660739\n",
            "28. URL_DigitCount: 1360.412324\n",
            "29. Entropy_Domain: 1326.917387\n",
            "30. longdomaintokenlen: 1232.807420\n",
            "31. path_token_count: 1194.164952\n",
            "32. dld_getArg: 1172.077420\n",
            "33. ArgLen: 1144.284617\n",
            "34. NumberRate_Extension: 1110.793808\n",
            "35. NumberRate_Domain: 1060.009570\n",
            "36. dld_path: 1053.555557\n",
            "37. dld_url: 1049.717127\n",
            "38. charcompace: 968.782089\n",
            "39. argDomanRatio: 963.224687\n",
            "40. subDirLen: 921.103503\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy: 0.9736\n",
            "Precision: 0.9736\n",
            "Recall: 0.9736\n",
            "F1 Score: 0.9736\n",
            "ROC AUC: 0.9988\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98      1628\n",
            "           1       0.97      0.99      0.98      1526\n",
            "           2       0.99      0.98      0.98      1332\n",
            "           3       0.95      0.94      0.94      1497\n",
            "           4       0.99      0.98      0.99      1359\n",
            "\n",
            "    accuracy                           0.97      7342\n",
            "   macro avg       0.97      0.97      0.97      7342\n",
            "weighted avg       0.97      0.97      0.97      7342\n",
            "\n"
          ]
        }
      ]
    }
  ]
}