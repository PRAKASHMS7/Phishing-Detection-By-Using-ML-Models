{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrPzpvQXl6iL6P37QNJiws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PRAKASHMS7/Phishing-Detection-By-Using-ML-Models/blob/main/Filter_Based_Approach/INFORMATION_GAIN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Load your data\n",
        "data = pd.read_csv('/content/All.csv')  # Change to your file path\n",
        "\n",
        "# Replace infinite values with NaN\n",
        "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "# Impute missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "data_imputed = imputer.fit_transform(data.select_dtypes(include=[np.number]))\n",
        "\n",
        "# Encode the target variable\n",
        "label_encoder = LabelEncoder()\n",
        "target = label_encoder.fit_transform(data['URL_Type_obf_Type'])  # Replace with your target column\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data_imputed)\n",
        "\n",
        "# Calculate Information Gain (Mutual Information)\n",
        "information_gain = mutual_info_classif(data_scaled, target)\n",
        "\n",
        "# Combine Information Gain scores with feature names\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': data.select_dtypes(include=[np.number]).columns,\n",
        "    'Information_Gain': information_gain\n",
        "})\n",
        "\n",
        "# Sort features by Information Gain in descending order\n",
        "important_features = feature_importance.sort_values(by='Information_Gain', ascending=False)\n",
        "\n",
        "# Select the top 40 features based on Information Gain\n",
        "num_features_to_select = 40\n",
        "selected_features = important_features.head(num_features_to_select)\n",
        "\n",
        "# Display the selected features along with their Information Gain scores\n",
        "print(\"Selected Features with Information Gain Scores:\")\n",
        "for i, row in selected_features.iterrows():\n",
        "    print(f\"{row['Feature']}: {row['Information_Gain']:.6f}\")\n",
        "\n",
        "# Filter the dataset to keep only the selected features\n",
        "data_selected = pd.DataFrame(data_scaled, columns=data.select_dtypes(include=[np.number]).columns)[selected_features['Feature'].values]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_selected, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train the model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "y_probs = model.predict_proba(X_test)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "roc_auc = roc_auc_score(y_test, y_probs, multi_class='ovr', average='macro')\n",
        "\n",
        "# Display the evaluation metrics\n",
        "print(\"\\nModel Evaluation Metrics:\")\n",
        "print(f\"Accuracy:    {accuracy:.4f}\")\n",
        "print(f\"Precision:   {precision:.4f}\")\n",
        "print(f\"Recall:      {recall:.4f}\")\n",
        "print(f\"F1 Score:    {f1:.4f}\")\n",
        "print(f\"ROC AUC:     {roc_auc:.4f}\\n\")\n",
        "\n",
        "# Generate and display classification report\n",
        "report = classification_report(y_test, y_pred, target_names=label_encoder.classes_, zero_division=0)\n",
        "print(\"Classification Report:\\n\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYVifi6M2OVf",
        "outputId": "7a18b069-94b4-4b9d-9259-535df2e86e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features with Information Gain Scores:\n",
            "Entropy_Domain: 1.080421\n",
            "pathurlRatio: 0.765498\n",
            "ArgUrlRatio: 0.754376\n",
            "argPathRatio: 0.752858\n",
            "argDomanRatio: 0.721424\n",
            "pathDomainRatio: 0.719932\n",
            "domainUrlRatio: 0.716639\n",
            "NumberRate_URL: 0.697755\n",
            "Entropy_DirectoryName: 0.674671\n",
            "CharacterContinuityRate: 0.654183\n",
            "NumberRate_FileName: 0.646348\n",
            "Entropy_Filename: 0.613215\n",
            "NumberRate_Extension: 0.557117\n",
            "avgpathtokenlen: 0.524524\n",
            "Entropy_Extension: 0.514930\n",
            "NumberRate_AfterPath: 0.500580\n",
            "Entropy_URL: 0.497531\n",
            "Entropy_Afterpath: 0.483519\n",
            "avgdomaintokenlen: 0.451762\n",
            "LongestPathTokenLength: 0.400869\n",
            "LongestVariableValue: 0.382361\n",
            "subDirLen: 0.363601\n",
            "pathLength: 0.362949\n",
            "urlLen: 0.362584\n",
            "NumberofDotsinURL: 0.360327\n",
            "ArgLen: 0.350518\n",
            "domainlength: 0.344909\n",
            "Querylength: 0.332099\n",
            "Query_LetterCount: 0.330046\n",
            "Extension_LetterCount: 0.324130\n",
            "Arguments_LongestWordLength: 0.305986\n",
            "host_letter_count: 0.305414\n",
            "domain_token_count: 0.299580\n",
            "SymbolCount_FileName: 0.297363\n",
            "tld: 0.293990\n",
            "SymbolCount_Domain: 0.291935\n",
            "Extension_DigitCount: 0.290854\n",
            "SymbolCount_Extension: 0.270366\n",
            "Query_DigitCount: 0.270122\n",
            "Filename_LetterCount: 0.268733\n",
            "\n",
            "Model Evaluation Metrics:\n",
            "Accuracy:    0.9710\n",
            "Precision:   0.9718\n",
            "Recall:      0.9708\n",
            "F1 Score:    0.9712\n",
            "ROC AUC:     0.9986\n",
            "\n",
            "Classification Report:\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Defacement       0.98      0.98      0.98      2434\n",
            "      benign       0.97      0.99      0.98      2329\n",
            "     malware       0.99      0.97      0.98      1984\n",
            "    phishing       0.93      0.95      0.94      2234\n",
            "        spam       0.99      0.97      0.98      2032\n",
            "\n",
            "    accuracy                           0.97     11013\n",
            "   macro avg       0.97      0.97      0.97     11013\n",
            "weighted avg       0.97      0.97      0.97     11013\n",
            "\n"
          ]
        }
      ]
    }
  ]
}